{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feature shape:  (9789, 256)\n",
      "Test feature shape:  (2611, 256)\n",
      "[[0.00463025 0.00625174 0.02074885 0.00350867 0.00772718 0.9571333 ]\n",
      " [0.00361925 0.00516757 0.0101166  0.00952851 0.00897152 0.96259654]\n",
      " [0.00272954 0.00753371 0.01087029 0.00805031 0.00639741 0.96441877]\n",
      " ...\n",
      " [0.01905265 0.92608374 0.02209971 0.00531116 0.02015011 0.00730256]\n",
      " [0.01536749 0.9254944  0.02625894 0.00545662 0.02040335 0.00701927]\n",
      " [0.01335277 0.02010148 0.8697333  0.00876164 0.01331125 0.07473968]]\n"
     ]
    }
   ],
   "source": [
    "# Import saved ResNet features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load Train Features\n",
    "train_features_df = pd.read_csv('Custom_CNN_fusion_Stratified/train_features_transformer.csv')\n",
    "train_labels = train_features_df['Label'].values\n",
    "groups_train = train_features_df['Image'].str[:].values  # ✅ Extract first 12 chars if patient ID\n",
    "pseudo_probs_train = train_features_df[\n",
    "    ['Pseudo_Prob_Class_0', 'Pseudo_Prob_Class_1', 'Pseudo_Prob_Class_2', \n",
    "     'Pseudo_Prob_Class_3', 'Pseudo_Prob_Class_4', 'Pseudo_Prob_Class_5']\n",
    "].values\n",
    "train_features = train_features_df.drop(columns=[\n",
    "    'Label', 'Image', 'Pseudo_Prob_Class_0', 'Pseudo_Prob_Class_1', 'Pseudo_Prob_Class_2', \n",
    "    'Pseudo_Prob_Class_3', 'Pseudo_Prob_Class_4', 'Pseudo_Prob_Class_5'\n",
    "]).values\n",
    "\n",
    "\n",
    "# Load Test Features\n",
    "test_features_df = pd.read_csv('Custom_CNN_fusion_Stratified/test_features_transformer.csv')\n",
    "test_labels = test_features_df['Label'].values\n",
    "groups_test = test_features_df['Image'].str[:].values  # ✅ Extract first 12 chars if patient ID\n",
    "pseudo_probs_test = test_features_df[\n",
    "    ['Pseudo_Prob_Class_0', 'Pseudo_Prob_Class_1', 'Pseudo_Prob_Class_2', \n",
    "     'Pseudo_Prob_Class_3', 'Pseudo_Prob_Class_4', 'Pseudo_Prob_Class_5']\n",
    "].values\n",
    "\n",
    "test_features = test_features_df.drop(columns=[\n",
    "    'Label', 'Image', 'Pseudo_Prob_Class_0', 'Pseudo_Prob_Class_1', 'Pseudo_Prob_Class_2', \n",
    "    'Pseudo_Prob_Class_3', 'Pseudo_Prob_Class_4', 'Pseudo_Prob_Class_5'\n",
    "]).values\n",
    "\n",
    "# Print the shape of the feature arrays\n",
    "print('Train feature shape: ', train_features.shape)\n",
    "print('Test feature shape: ', test_features.shape)\n",
    "\n",
    "\n",
    "# Print the pseudo probabilities\n",
    "print(pseudo_probs_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def graph_data_pseudo_prob_features(features, pseudo_probs, labels, max_neighbors=5):\n",
    "    \"\"\"\n",
    "    - Constructs a graph where nodes are connected based on their pseudo-labels.\n",
    "    - **No confidence-based filtering (low-confidence nodes are kept).**\n",
    "    - **Pseudo-probabilities are added as extra node features.**\n",
    "    \n",
    "    Args:\n",
    "        features (np.array): Original node feature matrix (num_nodes, feature_dim).\n",
    "        pseudo_probs (np.array): Pseudo-label probability distributions (num_nodes, num_classes).\n",
    "        labels (np.array): Ground truth labels (for evaluation, not used in connectivity).\n",
    "        max_neighbors (int): Maximum number of neighbors per node.\n",
    "\n",
    "    Returns:\n",
    "        PyG Data object with node features including pseudo probabilities.\n",
    "    \"\"\"\n",
    "    num_nodes = features.shape[0]\n",
    "    feature_tensor = torch.tensor(features, dtype=torch.float)\n",
    "    pseudo_probs_tensor = torch.tensor(pseudo_probs, dtype=torch.float)\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    # ✅ Compute pseudo-labels from pseudo_probs\n",
    "    pseudo_labels = pseudo_probs.argmax(axis=1)\n",
    "\n",
    "    # ✅ Step 1: Initialize adjacency matrix\n",
    "    adjacency_matrix = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "    # ✅ Step 2: Group nodes by pseudo-labels\n",
    "    pseudo_label_groups = {c: np.where(pseudo_labels == c)[0] for c in np.unique(pseudo_labels)}\n",
    "\n",
    "    # ✅ Step 3: Connect nodes within the same pseudo-label group\n",
    "    for node_idx in range(num_nodes):\n",
    "        node_label = pseudo_labels[node_idx]\n",
    "        same_class_nodes = pseudo_label_groups[node_label]\n",
    "\n",
    "        # Remove self-loop\n",
    "        same_class_nodes = same_class_nodes[same_class_nodes != node_idx]\n",
    "\n",
    "        # Limit number of connections\n",
    "        if len(same_class_nodes) > max_neighbors:\n",
    "            same_class_nodes = np.random.choice(same_class_nodes, max_neighbors, replace=False)\n",
    "\n",
    "        # Create connections\n",
    "        adjacency_matrix[node_idx, same_class_nodes] = 1\n",
    "\n",
    "    # ✅ Step 4: Convert adjacency matrix to edge index format\n",
    "    edge_index = np.array(np.nonzero(adjacency_matrix))\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "\n",
    "    # ✅ Step 5: Concatenate pseudo probabilities as additional node features\n",
    "    node_features_with_probs = torch.cat([feature_tensor, pseudo_probs_tensor], dim=1)  # (num_nodes, feature_dim + num_classes)\n",
    "\n",
    "    # ✅ Step 6: Create PyG Data object\n",
    "    data = Data(x=node_features_with_probs, edge_index=edge_index, y=labels_tensor)\n",
    "    \n",
    "    pseudo_labels_tensor = torch.tensor(pseudo_labels, dtype=torch.long)\n",
    "    data.pseudo_labels = pseudo_labels_tensor\n",
    "    data.pseudo_probs = pseudo_probs_tensor  # ✅ Each node retains its full probability distribution\n",
    "\n",
    "    return data\n",
    "\n",
    "# ✅ Example Usage\n",
    "train_graph = graph_data_pseudo_prob_features(train_features, pseudo_probs_train, train_labels, max_neighbors=3)\n",
    "test_graph = graph_data_pseudo_prob_features(test_features, pseudo_probs_test, test_labels, max_neighbors=3)\n",
    "\n",
    "print(train_graph)\n",
    "print(f\"Train Graph - Nodes: {train_graph.num_nodes}, Edges: {train_graph.num_edges}\")\n",
    "print(f\"Test Graph - Nodes: {test_graph.num_nodes}, Edges: {test_graph.num_edges}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "def graph_data_separate_confidence(features, pseudo_probs, labels, image_names, max_neighbors=5, confidence_threshold=0.58, filter_test=False):\n",
    "    \"\"\"\n",
    "    - Constructs graph based on high-confidence pseudo-labels.\n",
    "    - **For test data only**, prints accuracy metrics and visualizes confusion matrices.\n",
    "    - **Pseudo-labels are now inferred from pseudo_probs (no need to pass pseudo_labels explicitly)**.\n",
    "    \"\"\"\n",
    "    num_nodes = features.shape[0]\n",
    "\n",
    "    # ✅ Compute pseudo-labels dynamically from pseudo_probs\n",
    "    pseudo_labels = pseudo_probs.argmax(axis=1)  # Get highest-confidence class for each node\n",
    "    assigned_pseudo_probs = pseudo_probs[np.arange(num_nodes), pseudo_labels]  # Keep confidence of assigned class\n",
    "\n",
    "    # ✅ Identify high-confidence & low-confidence nodes\n",
    "    if filter_test:\n",
    "        high_confidence_indices = np.where(assigned_pseudo_probs >= confidence_threshold)[0]  # High-confidence nodes\n",
    "        low_confidence_indices = np.where(assigned_pseudo_probs < confidence_threshold)[0]  # Low-confidence nodes\n",
    "        discarded_images = [image_names[i] for i in low_confidence_indices]  # Store discarded image names\n",
    "        kept_images = [image_names[i] for i in high_confidence_indices]  # Store kept image names\n",
    "    else:\n",
    "        high_confidence_indices = np.arange(num_nodes)  # Keep all nodes for training\n",
    "        low_confidence_indices = []\n",
    "        discarded_images = []  # No images are discarded in training\n",
    "        kept_images = []\n",
    "\n",
    "    high_confidence_features = features[high_confidence_indices]\n",
    "    high_confidence_pseudo_labels = pseudo_labels[high_confidence_indices]\n",
    "    high_confidence_true_labels = labels[high_confidence_indices]  # True labels for high-confidence nodes\n",
    "\n",
    "    # ✅ Step 1: Connect high-confidence nodes based on pseudo-labels\n",
    "    adjacency_matrix = np.zeros((len(high_confidence_indices), len(high_confidence_indices)))\n",
    "\n",
    "    for idx, i in enumerate(high_confidence_indices):\n",
    "        same_pseudo_label_indices = high_confidence_indices[high_confidence_pseudo_labels == high_confidence_pseudo_labels[idx]]\n",
    "\n",
    "        # Exclude the current node\n",
    "        same_pseudo_label_indices = same_pseudo_label_indices[same_pseudo_label_indices != i]\n",
    "\n",
    "        # Limit to max_neighbors\n",
    "        if len(same_pseudo_label_indices) > max_neighbors:\n",
    "            same_pseudo_label_indices = np.random.choice(same_pseudo_label_indices, max_neighbors, replace=True)\n",
    "\n",
    "        for j in same_pseudo_label_indices:\n",
    "            adjacency_matrix[idx, np.where(high_confidence_indices == j)[0][0]] = 1  # Connect similar pseudo-labeled nodes\n",
    "\n",
    "    # ✅ Step 2: Convert adjacency matrix to edge index\n",
    "    edge_index = np.array(np.nonzero(adjacency_matrix))\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "\n",
    "    # ✅ Step 3: Ensure only high-confidence nodes are kept in the graph (for test)\n",
    "    filtered_feature_tensor = torch.tensor(high_confidence_features, dtype=torch.float)\n",
    "    filtered_labels_tensor = torch.tensor(high_confidence_true_labels, dtype=torch.long)\n",
    "\n",
    "    # ✅ Step 4: Compute Accuracy for High-Confidence & Low-Confidence Nodes\n",
    "    if filter_test:\n",
    "       \n",
    "\n",
    "        if len(low_confidence_indices) > 0:\n",
    "            low_confidence_true_labels = labels[low_confidence_indices]\n",
    "            low_confidence_pseudo_labels = pseudo_labels[low_confidence_indices]\n",
    "\n",
    "\n",
    "            # ✅ Confusion Matrix & Visualizations\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "            # 🔹 **Ground Truth Label Distribution**\n",
    "            axes[0].hist(low_confidence_true_labels, bins=np.arange(low_confidence_true_labels.min(), low_confidence_true_labels.max() + 2) - 0.5,\n",
    "                         alpha=0.7, color='blue', edgecolor='black', label='True Labels')\n",
    "            axes[0].set_xticks(range(low_confidence_true_labels.min(), low_confidence_true_labels.max() + 1))\n",
    "            axes[0].set_xlabel('Class Labels')\n",
    "            axes[0].set_ylabel('Count')\n",
    "            axes[0].set_title('Ground Truth Label Distribution (Low Confidence)')\n",
    "            axes[0].legend()\n",
    "\n",
    "            # 🔹 **Pseudo-Label Distribution**\n",
    "            axes[1].hist(low_confidence_pseudo_labels, bins=np.arange(low_confidence_pseudo_labels.min(), low_confidence_pseudo_labels.max() + 2) - 0.5,\n",
    "                         alpha=0.7, color='red', edgecolor='black', label='Pseudo Labels')\n",
    "            axes[1].set_xticks(range(low_confidence_pseudo_labels.min(), low_confidence_pseudo_labels.max() + 1))\n",
    "            axes[1].set_xlabel('Pseudo Labels')\n",
    "            axes[1].set_ylabel('Count')\n",
    "            axes[1].set_title('Pseudo Label Distribution (Low Confidence)')\n",
    "            axes[1].legend()\n",
    "\n",
    "            # 🔹 **Confusion Matrix**\n",
    "            cm = confusion_matrix(low_confidence_true_labels, low_confidence_pseudo_labels)\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(low_confidence_true_labels),\n",
    "                        yticklabels=np.unique(low_confidence_true_labels), ax=axes[2])\n",
    "            axes[2].set_xlabel(\"Predicted Pseudo Labels\")\n",
    "            axes[2].set_ylabel(\"True Labels\")\n",
    "            axes[2].set_title(\"Confusion Matrix (Low Confidence Nodes)\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    # ✅ Create PyTorch Geometric Graph Data\n",
    "    data = Data(x=filtered_feature_tensor, edge_index=edge_index, y=filtered_labels_tensor)\n",
    "    \n",
    "    pseudo_labels_tensor = torch.tensor(pseudo_labels, dtype=torch.long)\n",
    "    pseudo_probs_tensor = torch.tensor(assigned_pseudo_probs, dtype=torch.float)  # ✅ Single probability per node\n",
    "    data.pseudo_labels = pseudo_labels_tensor[high_confidence_indices]\n",
    "    data.pseudo_probs = pseudo_probs_tensor[high_confidence_indices]\n",
    "    \n",
    "    return data, discarded_images, kept_images  # ✅ Return discarded images\n",
    "\n",
    "# ✅ Example Usage\n",
    "train_graph, _, _ = graph_data_separate_confidence(train_features, pseudo_probs_train, train_labels, groups_train, max_neighbors=10, filter_test=False)\n",
    "test_graph, discarded_test_images, kept_images = graph_data_separate_confidence(test_features, pseudo_probs_test, test_labels, groups_test, max_neighbors=10, filter_test=True)\n",
    "\n",
    "print(train_graph)\n",
    "print(f\"Train Graph - Nodes: {train_graph.num_nodes}, Edges: {train_graph.num_edges}\")\n",
    "print(f\"Test Graph - Nodes: {test_graph.num_nodes}, Edges: {test_graph.num_edges}\")\n",
    "\n",
    "# ✅ Print the discarded images for review\n",
    "print(\"Discarded Test Images (Low Confidence Nodes):\")\n",
    "print(discarded_test_images)\n",
    "\n",
    "# ✅ Print the kept test images for review\n",
    "print(\"Kept Test Images (High Confidence Nodes):\")\n",
    "print(kept_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mertdaloglu/anaconda3/envs/gcnn_project/lib/python3.9/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: dlopen(/Users/mertdaloglu/anaconda3/envs/gcnn_project/lib/python3.9/site-packages/libpyg.so, 0x0006): Library not loaded: /Library/Frameworks/Python.framework/Versions/3.9/Python\n",
      "  Referenced from: <2695749E-A917-3F14-B0DA-2A4914D2853D> /Users/mertdaloglu/anaconda3/envs/gcnn_project/lib/python3.9/site-packages/libpyg.so\n",
      "  Reason: tried: '/Library/Frameworks/Python.framework/Versions/3.9/Python' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e' or 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Library/Frameworks/Python.framework/Versions/3.9/Python' (no such file), '/Library/Frameworks/Python.framework/Versions/3.9/Python' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e' or 'arm64'))\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/Users/mertdaloglu/anaconda3/envs/gcnn_project/lib/python3.9/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: dlopen(/Users/mertdaloglu/anaconda3/envs/gcnn_project/lib/python3.9/site-packages/libpyg.so, 0x0006): Library not loaded: /Library/Frameworks/Python.framework/Versions/3.9/Python\n",
      "  Referenced from: <2695749E-A917-3F14-B0DA-2A4914D2853D> /Users/mertdaloglu/anaconda3/envs/gcnn_project/lib/python3.9/site-packages/libpyg.so\n",
      "  Reason: tried: '/Library/Frameworks/Python.framework/Versions/3.9/Python' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e' or 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/Library/Frameworks/Python.framework/Versions/3.9/Python' (no such file), '/Library/Frameworks/Python.framework/Versions/3.9/Python' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e' or 'arm64'))\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[9789, 256], edge_index=[2, 39156], edge_attr=[39156], y=[9789], pseudo_probs=[9789])\n",
      "Train Graph - Nodes: 9789, Edges: 39156\n",
      "Test Graph - Nodes: 2611, Edges: 10444\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data\n",
    "import random\n",
    "\n",
    "def generate_confidence_weighted_graph(features, pseudo_labels, pseudo_probs, labels, max_neighbors=3):\n",
    "    \"\"\"\n",
    "    Constructs a graph where:\n",
    "    - Nodes are connected based on their pseudo-labels.\n",
    "    - Edge weights are assigned based on confidence scores.\n",
    "    - No nodes are removed (low-confidence nodes are retained but receive lower edge weights).\n",
    "    \n",
    "    Parameters:\n",
    "    - features: NumPy array of feature vectors.\n",
    "    - pseudo_labels: NumPy array of pseudo-labels.\n",
    "    - pseudo_probs: NumPy array of confidence scores.\n",
    "    - labels: Ground-truth labels (for evaluation purposes).\n",
    "    - max_neighbors: Maximum number of neighbors for each node.\n",
    "\n",
    "    Returns:\n",
    "    - PyTorch Geometric `Data` object containing the graph.\n",
    "    \"\"\"\n",
    "    num_nodes = features.shape[0]\n",
    "    \n",
    "    # Convert to PyTorch tensors\n",
    "    feature_tensor = torch.tensor(features, dtype=torch.float)\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    adjacency_matrix = np.zeros((num_nodes, num_nodes))\n",
    "    edge_weights = np.zeros((num_nodes, num_nodes))  # Edge weight matrix\n",
    "\n",
    "    for i in range(num_nodes):\n",
    "        same_pseudo_label_indices = np.where(pseudo_labels == pseudo_labels[i])[0]\n",
    "        \n",
    "        # Exclude self-connections\n",
    "        same_pseudo_label_indices = same_pseudo_label_indices[same_pseudo_label_indices != i]\n",
    "        \n",
    "        # Limit to max_neighbors\n",
    "        if len(same_pseudo_label_indices) > max_neighbors:\n",
    "            selected_neighbors = np.random.choice(same_pseudo_label_indices, max_neighbors, replace=False)\n",
    "        else:\n",
    "            selected_neighbors = same_pseudo_label_indices\n",
    "        \n",
    "        # Assign edges with confidence-based weights\n",
    "        for j in selected_neighbors:\n",
    "            adjacency_matrix[i, j] = 1\n",
    "            edge_weights[i, j] = (pseudo_probs[i] + pseudo_probs[j]) / 2  # Confidence-weighted edges\n",
    "    \n",
    "    # Add self-loops (confidence weight remains 1.0 for self-loops)\n",
    "    np.fill_diagonal(adjacency_matrix, 1)\n",
    "    np.fill_diagonal(edge_weights, 1.0)\n",
    "\n",
    "    # Convert adjacency matrix to edge index\n",
    "    edge_index = np.array(np.nonzero(adjacency_matrix))\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "\n",
    "    # Convert edge weights to PyTorch tensor\n",
    "    edge_weights = edge_weights[edge_index[0], edge_index[1]]\n",
    "    edge_weights = torch.tensor(edge_weights, dtype=torch.float)\n",
    "\n",
    "    # Create PyTorch Geometric Graph Data Object\n",
    "    data = Data(x=feature_tensor, edge_index=edge_index, y=labels_tensor, edge_attr=edge_weights)\n",
    "    data.pseudo_probs = torch.tensor(pseudo_probs, dtype=torch.float)\n",
    "\n",
    "    return data\n",
    "\n",
    "train_graph = generate_confidence_weighted_graph(train_features, pseudo_labels_train, pseudo_probs_train, train_labels)\n",
    "test_graph = generate_confidence_weighted_graph(test_features, pseudo_labels_test, pseudo_probs_test, test_labels)\n",
    "\n",
    "print(train_graph)\n",
    "print(f\"Train Graph - Nodes: {train_graph.num_nodes}, Edges: {train_graph.num_edges}\")\n",
    "print(f\"Test Graph - Nodes: {test_graph.num_nodes}, Edges: {test_graph.num_edges}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/dsypcq4n5hg6hh5qdss0ly540000gn/T/ipykernel_1347/2852487311.py:30: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  color_map = plt.cm.get_cmap('jet', len(unique_labels))  # Generate color map\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.utils import to_networkx\n",
    "import numpy as np\n",
    "\n",
    "def visualize_subgraph(data):\n",
    "    \"\"\"\n",
    "    Convert a PyTorch Geometric graph into a NetworkX graph and visualize a small subgraph.\n",
    "\n",
    "    Args:\n",
    "        data (torch_geometric.data.Data): Graph data.\n",
    "       \n",
    "    \"\"\"\n",
    "    \n",
    "    num_nodes = data.num_nodes\n",
    "    \n",
    "    # Convert PyG graph to NetworkX format\n",
    "    G = to_networkx(data, to_undirected=True)\n",
    "\n",
    "    # Extract a subset of nodes\n",
    "    sub_nodes = list(G.nodes)[:num_nodes]  # Select first `num_nodes`\n",
    "    subgraph = G.subgraph(sub_nodes)\n",
    "\n",
    "    # Assign colors based on class labels\n",
    "    node_labels = np.array([data.y[i].item() for i in sub_nodes])  # Get labels of selected nodes\n",
    "    unique_labels = np.unique(node_labels)  # Unique class labels\n",
    "\n",
    "    # Create a color map for unique class labels\n",
    "    color_map = plt.cm.get_cmap('jet', len(unique_labels))  # Generate color map\n",
    "    label_color_mapping = {label: color_map(i / len(unique_labels)) for i, label in enumerate(unique_labels)}  # Map labels to colors\n",
    "    node_colors = [label_color_mapping[label] for label in node_labels]  # Assign colors\n",
    "\n",
    "    # Plot the graph\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    nx.draw(subgraph, with_labels=False, node_size=50, node_color=node_colors)\n",
    "\n",
    "    plt.title(f\"Visualization of First {num_nodes} Nodes in the Graph\")\n",
    "\n",
    "    # Create a legend for the node colors\n",
    "    legend_patches = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=label_color_mapping[label], markersize=8, label=f\"Class {label}\") \n",
    "                      for label in unique_labels]\n",
    "    plt.legend(handles=legend_patches, title=\"Node Classes\", loc=\"upper right\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to visualize the graph (first 55 nodes)\n",
    "visualize_subgraph(test_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from utils import GCNNClassifier, GCNN_Dot_Product, GCNN_Concat_Attention, GCNN_Prod_Res, GATClassifier, GraphSAGEClassifier, GNClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Choose and Define the model\n",
    "in_channels = train_graph.x.shape[1]  # (feature vector size)\n",
    "hidden_channels = 256\n",
    "num_classes = 6\n",
    "model = GNClassifier(in_channels, hidden_channels, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def confidence_weighted_loss(preds, true_labels, confidence_scores, beta=5):\n",
    "    \"\"\"\n",
    "    Computes confidence-weighted cross-entropy loss using a logarithmic scaling function.\n",
    "\n",
    "    - beta: Scaling factor. Higher values increase the gap between high- and low-confidence nodes.\n",
    "    \"\"\"\n",
    "    ce_loss = F.cross_entropy(preds, true_labels, reduction='none')\n",
    "\n",
    "    # Log-transformed confidence scaling\n",
    "    scaled_confidence = torch.log1p(beta * confidence_scores.max())  # log(1 + beta * c)\n",
    "\n",
    "    weighted_loss = (scaled_confidence * ce_loss).mean()\n",
    "\n",
    "    return weighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|          | 1/150 [00:20<52:01, 20.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 144.9695, Val Loss: 21.9092, Train Acc: 0.33, Val Acc: 0.6841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1%|▏         | 2/150 [00:50<1:04:13, 26.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 83.9766, Val Loss: 16.9624, Train Acc: 0.69, Val Acc: 0.7372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 3/150 [01:21<1:09:30, 28.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Train Loss: 64.0929, Val Loss: 13.9600, Train Acc: 0.75, Val Acc: 0.8105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 4/150 [01:48<1:07:45, 27.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Train Loss: 52.4628, Val Loss: 11.9007, Train Acc: 0.82, Val Acc: 0.8295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 5/150 [02:13<1:04:50, 26.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss: 44.4664, Val Loss: 10.0644, Train Acc: 0.84, Val Acc: 0.8365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   4%|▍         | 6/150 [02:38<1:02:41, 26.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Train Loss: 37.5160, Val Loss: 8.6154, Train Acc: 0.84, Val Acc: 0.8381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▍         | 7/150 [03:07<1:04:43, 27.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Train Loss: 32.0764, Val Loss: 7.4427, Train Acc: 0.85, Val Acc: 0.8390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   5%|▌         | 8/150 [03:27<58:33, 24.74s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Train Loss: 27.6808, Val Loss: 6.7003, Train Acc: 0.85, Val Acc: 0.8410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   6%|▌         | 9/150 [03:45<53:01, 22.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Train Loss: 24.9323, Val Loss: 5.9819, Train Acc: 0.85, Val Acc: 0.8447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 10/150 [04:03<49:32, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Train Loss: 22.3058, Val Loss: 5.3642, Train Acc: 0.85, Val Acc: 0.8464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   7%|▋         | 11/150 [04:26<50:20, 21.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Train Loss: 20.0358, Val Loss: 4.8128, Train Acc: 0.86, Val Acc: 0.8501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   8%|▊         | 12/150 [04:50<51:43, 22.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Train Loss: 17.9301, Val Loss: 4.4063, Train Acc: 0.86, Val Acc: 0.8587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▊         | 13/150 [05:08<48:31, 21.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Train Loss: 16.4342, Val Loss: 3.9858, Train Acc: 0.87, Val Acc: 0.8670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 14/150 [05:27<46:32, 20.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Train Loss: 14.9243, Val Loss: 3.6256, Train Acc: 0.89, Val Acc: 0.8764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 15/150 [05:47<45:20, 20.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Train Loss: 13.5042, Val Loss: 3.3433, Train Acc: 0.90, Val Acc: 0.8880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█         | 16/150 [06:16<50:58, 22.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Train Loss: 12.3838, Val Loss: 3.0568, Train Acc: 0.92, Val Acc: 0.8954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  11%|█▏        | 17/150 [06:41<52:02, 23.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Train Loss: 11.2841, Val Loss: 2.9083, Train Acc: 0.93, Val Acc: 0.9057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  12%|█▏        | 18/150 [07:09<54:41, 24.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Train Loss: 10.5296, Val Loss: 2.7975, Train Acc: 0.94, Val Acc: 0.9114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 19/150 [07:29<51:24, 23.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Train Loss: 10.2284, Val Loss: 2.7058, Train Acc: 0.95, Val Acc: 0.9193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  13%|█▎        | 20/150 [07:52<50:28, 23.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Train Loss: 9.6349, Val Loss: 2.4098, Train Acc: 0.96, Val Acc: 0.9250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  14%|█▍        | 21/150 [08:23<54:53, 25.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Train Loss: 8.5214, Val Loss: 2.2264, Train Acc: 0.96, Val Acc: 0.9255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▍        | 22/150 [08:44<51:51, 24.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Train Loss: 8.0416, Val Loss: 2.2611, Train Acc: 0.97, Val Acc: 0.9226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  15%|█▌        | 23/150 [09:08<51:08, 24.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Train Loss: 7.9366, Val Loss: 1.9562, Train Acc: 0.97, Val Acc: 0.9222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  16%|█▌        | 24/150 [09:33<51:36, 24.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Train Loss: 6.8742, Val Loss: 2.0096, Train Acc: 0.97, Val Acc: 0.9209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 25/150 [09:58<51:00, 24.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Train Loss: 7.0822, Val Loss: 1.9662, Train Acc: 0.97, Val Acc: 0.9213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  17%|█▋        | 26/150 [10:21<49:38, 24.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Train Loss: 6.5406, Val Loss: 1.7251, Train Acc: 0.97, Val Acc: 0.9205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  18%|█▊        | 27/150 [10:43<48:20, 23.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Train Loss: 5.7142, Val Loss: 1.8051, Train Acc: 0.97, Val Acc: 0.9201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▊        | 28/150 [11:11<50:27, 24.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Train Loss: 6.0561, Val Loss: 1.6114, Train Acc: 0.97, Val Acc: 0.9197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  19%|█▉        | 29/150 [11:39<52:09, 25.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Train Loss: 5.1990, Val Loss: 1.5676, Train Acc: 0.97, Val Acc: 0.9201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 30/150 [11:59<47:58, 23.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Train Loss: 5.0407, Val Loss: 1.5865, Train Acc: 0.97, Val Acc: 0.9197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 31/150 [12:16<43:32, 21.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Train Loss: 5.1980, Val Loss: 1.4110, Train Acc: 0.97, Val Acc: 0.9193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██▏       | 32/150 [12:33<40:09, 20.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Train Loss: 4.4772, Val Loss: 1.4576, Train Acc: 0.97, Val Acc: 0.9197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  22%|██▏       | 33/150 [12:52<39:01, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Train Loss: 4.5156, Val Loss: 1.4169, Train Acc: 0.97, Val Acc: 0.9197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 34/150 [13:11<38:14, 19.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Train Loss: 4.3409, Val Loss: 1.2902, Train Acc: 0.97, Val Acc: 0.9197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  23%|██▎       | 35/150 [13:28<36:30, 19.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Train Loss: 3.9483, Val Loss: 1.3185, Train Acc: 0.97, Val Acc: 0.9201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  24%|██▍       | 36/150 [13:47<35:51, 18.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Train Loss: 4.0846, Val Loss: 1.2382, Train Acc: 0.97, Val Acc: 0.9197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▍       | 37/150 [14:11<38:28, 20.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Train Loss: 3.7295, Val Loss: 1.2931, Train Acc: 0.97, Val Acc: 0.9197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  25%|██▌       | 38/150 [14:30<37:18, 19.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Train Loss: 3.8540, Val Loss: 1.2244, Train Acc: 0.97, Val Acc: 0.9205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  26%|██▌       | 39/150 [14:51<37:46, 20.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Train Loss: 3.6611, Val Loss: 1.1742, Train Acc: 0.97, Val Acc: 0.9205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 40/150 [15:09<36:07, 19.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Train Loss: 3.6101, Val Loss: 1.1540, Train Acc: 0.97, Val Acc: 0.9209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  27%|██▋       | 40/150 [15:16<42:00, 22.92s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 46\u001b[0m\n\u001b[1;32m     41\u001b[0m out \u001b[38;5;241m=\u001b[39m model(train_graph\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mto(device), train_graph\u001b[38;5;241m.\u001b[39medge_index\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#train_loss = criterion(out, train_graph.y.to(device))\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#train_loss = confidence_weighted_loss(out, train_graph.y.to(device), train_graph.pseudo_probs.to(device))\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     49\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Desktop/PONS_GCNN/utils/GN_models.py:504\u001b[0m, in \u001b[0;36mGNClassifier.loss\u001b[0;34m(self, graph, augmentation)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_id \u001b[38;5;129;01min\u001b[39;00m torch\u001b[38;5;241m.\u001b[39munique(graph\u001b[38;5;241m.\u001b[39my):\n\u001b[1;32m    503\u001b[0m     class_mask \u001b[38;5;241m=\u001b[39m (graph\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m==\u001b[39m class_id)\n\u001b[0;32m--> 504\u001b[0m     class_centroid \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmentation\u001b[49m\u001b[43m)\u001b[49m[class_mask], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \n\u001b[1;32m    505\u001b[0m     class_centroids\u001b[38;5;241m.\u001b[39mappend(class_centroid)\n\u001b[1;32m    507\u001b[0m class_centroids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(class_centroids)  \u001b[38;5;66;03m# Shape: (num_classes, feature_dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/PONS_GCNN/utils/GN_models.py:439\u001b[0m, in \u001b[0;36mGNClassifier.forward\u001b[0;34m(self, x, edge_index, augmentation)\u001b[0m\n\u001b[1;32m    436\u001b[0m     noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(x) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.01\u001b[39m  \u001b[38;5;66;03m# Small noise factor\u001b[39;00m\n\u001b[1;32m    437\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m noise  \u001b[38;5;66;03m# Add noise to node features\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/folders/gk/dsypcq4n5hg6hh5qdss0ly540000gn/T/utils.GN_models_GNClassifier_propagate_z54fs45m.py:190\u001b[0m, in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, size)\u001b[0m\n\u001b[1;32m    180\u001b[0m             kwargs \u001b[38;5;241m=\u001b[39m CollectArgs(\n\u001b[1;32m    181\u001b[0m                 x_i\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_i\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    182\u001b[0m                 x_j\u001b[38;5;241m=\u001b[39mhook_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_j\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m                 x\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mx,\n\u001b[1;32m    187\u001b[0m             )\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# End Message Forward Pre Hook #########################################\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_i\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_j\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_j\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# Begin Message Forward Hook ###########################################\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "File \u001b[0;32m~/Desktop/PONS_GCNN/utils/GN_models.py:454\u001b[0m, in \u001b[0;36mGNClassifier.message\u001b[0;34m(self, x_i, x_j)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03mCompute messages from source (x_j) to target (x_i).\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    Tensor: Computed messages.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# Compute L1 norm for regularization\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_j\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Compute message for edge\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1_penalty \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(message, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# L1 norm of message vectors\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;66;03m# Compute cosine similarity between message vectors\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/gcnn_project/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gcnn_project/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/gcnn_project/lib/python3.9/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/gcnn_project/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/gcnn_project/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/gcnn_project/lib/python3.9/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "# Get unique classes\n",
    "unique_classes = np.unique(train_labels)\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=unique_classes, y=train_labels)\n",
    "# Convert to PyTorch tensor\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "# Early stopping parameters (based on validation accuracy)\n",
    "best_val_acc = 0.0\n",
    "patience = 150\n",
    "counter = 0\n",
    "\n",
    "# Lists to store losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 150  # Set high, but will stop early if necessary\n",
    "\n",
    "\n",
    "# Define loss function and optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-2)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "# ADD LEARNING RATE SCHEDULER\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=num_epochs//5, gamma=0.5)  # Reduce LR every 50 epochs\n",
    "\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Training\", total=num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    out = model(train_graph.x.to(device), train_graph.edge_index.to(device))\n",
    "    \n",
    "    \n",
    "    #train_loss = criterion(out, train_graph.y.to(device))\n",
    "    #train_loss = confidence_weighted_loss(out, train_graph.y.to(device), train_graph.pseudo_probs.to(device))\n",
    "    train_loss = model.loss(train_graph.to(device), augmentation=False)\n",
    "    \n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step() \n",
    "    \n",
    "    # Compute training accuracy\n",
    "    pred_train = out.argmax(dim=1)\n",
    "    train_acc = (pred_train == train_graph.y.to(device)).sum().item() / train_graph.y.size(0)\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_out = model(test_graph.x.to(device), test_graph.edge_index.to(device))\n",
    "\n",
    "        #val_loss = criterion(val_out, test_graph.y.to(device))\n",
    "        #val_loss = confidence_weighted_loss(val_out, test_graph.y.to(device), test_graph.pseudo_probs.to(device))\n",
    "        val_loss = model.loss(test_graph.to(device), augmentation=False)\n",
    "         \n",
    "        # Convert logits to probabilities\n",
    "        val_probs = torch.softmax(val_out, dim=1)  \n",
    "        pred_val = val_probs.argmax(dim=1)  # Get class predictions\n",
    "        # Compute validation accuracy\n",
    "        val_acc = (pred_val == test_graph.y.to(device)).sum().item() / test_graph.y.size(0)\n",
    "\n",
    "    # Store losses\n",
    "    train_losses.append(train_loss.item())\n",
    "    val_losses.append(val_loss.item())\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {train_loss.item():.4f}, Val Loss: {val_loss.item():.4f}, Train Acc: {train_acc:.2f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Early Stopping Logic (Based on Validation Accuracy)\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), \"best_gcnn.pth\")  # Save best model\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f\"Stopping early at epoch {epoch+1}. Best Val Acc: {best_val_acc:.4f}\")\n",
    "            break\n",
    "\n",
    "# Plot Loss Curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gk/dsypcq4n5hg6hh5qdss0ly540000gn/T/ipykernel_6356/3483976095.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_gcnn.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9341\n"
     ]
    }
   ],
   "source": [
    "# Load the best model best_gcnn.pth and evaluate on the test set\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load(\"best_gcnn.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Test set evaluation\n",
    "with torch.no_grad():\n",
    "    test_out = model(test_graph.x.to(device), test_graph.edge_index.to(device))\n",
    "    test_probs = torch.softmax(test_out, dim=1)  # Convert logits to probabilities\n",
    "    pred_test = test_probs.argmax(dim=1)  # Get class predictions\n",
    "    test_acc = (pred_test == test_graph.y.to(device)).sum().item() / test_graph.y.size(0)\n",
    "\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcnn_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
