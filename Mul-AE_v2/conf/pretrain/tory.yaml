# @package _global_
# GENERAL
seed: 123
gpu_ids: 0,
backend: nccl
workers: 4


# EPOCH
epochs: 30
save_epochs: 30
warmup_epochs: 10

# LOG ROOT
log_root:  /home/guest/Work/Xiang/logs/Mul-AE
print_freq: 500

# MODEL
arch: 
  _target_: srcs.model.mul_ae.create_model
  model_name: mae_vit_base_patch16
  pth_path: /home/guest/Work/Xiang/checkpoints/mae_pretrain_vit_base.pth

mask_ratio: 0.5

# DATASET
data_name: BP4D+
csv_root: /home/guest/Work/Xiang/csv/BP4D+/all_frames/depth_sample/
texture_root:  /home/tory/Data/${data_name}/All_crop
depth_root: /home/tory/Data/${data_name}/AllDepth
modalities: ['texture', 'depth']
training: true
batch_size: 64
fold: 'data'

# TRANSFORM
input_size: 224


loss_scaler:
  _target_: srcs.model.loss.NativeScalerWithGradNormCount

# METRIC
metrics:
  - _target_: srcs.model.metric.F1

# OPTIMIZER
lr: 0.0002
min_lr: 1.e-6
weight_decay: 0.05

lr_adjust:
  _target_: srcs.utils.lrd.Adjust_LearningRater
  lr_steps: []
  lr_beta: [0.1]
  is_cosine_decay: true

trainer:
  _target_: srcs.trainer.trainer_pretrain.Trainer

