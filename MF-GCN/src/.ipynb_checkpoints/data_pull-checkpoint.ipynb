{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "501a0c29-03f6-435a-a17a-8426d3150911",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://pons_aws_data/backup/datasets/BUSI/fold1.zip...\n",
      "Copying gs://pons_aws_data/backup/datasets/BUSI/fold2.zip...                    \n",
      "Copying gs://pons_aws_data/backup/datasets/BUSI/fold3.zip...                    \n",
      "\\ [3/3 files][  1.4 GiB/  1.4 GiB] 100% Done  79.9 MiB/s ETA 00:00:00           \n",
      "Operation completed over 3 objects/1.4 GiB.                                      \n",
      "total 1.5G\n",
      "-rw-r--r-- 1 jupyter jupyter 487M Aug 19 12:44 fold1.zip\n",
      "-rw-r--r-- 1 jupyter jupyter 487M Aug 19 12:44 fold2.zip\n",
      "-rw-r--r-- 1 jupyter jupyter 487M Aug 19 12:44 fold3.zip\n"
     ]
    }
   ],
   "source": [
    "# Create local directory\n",
    "!mkdir -p /home/jupyter/cloud_direct\n",
    "\n",
    "# Copy data from your GCS bucket into the local directory\n",
    "!gsutil -m cp -r gs://pons_aws_data/backup/datasets/BUSI/* /home/jupyter/cloud_direct/\n",
    "\n",
    "# Verify files\n",
    "!ls -lh /home/jupyter/cloud_direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cfc8579-af6b-4403-9a89-100434e3e2db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted fold1.zip to /home/jupyter/fold1\n",
      "Extracted fold2.zip to /home/jupyter/fold2\n",
      "Extracted fold3.zip to /home/jupyter/fold3\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "folds = [\"fold1.zip\", \"fold2.zip\", \"fold3.zip\"]\n",
    "\n",
    "for fold in folds:\n",
    "    zip_path = f\"/home/jupyter/cloud_direct/{fold}\"\n",
    "    extract_dir = f\"/home/jupyter/{fold.replace('.zip', '')}\"\n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "\n",
    "    print(f\"Extracted {fold} to {extract_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e2aba7-1883-46b0-bf04-fe259f1e38bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bae64fba-9946-469a-a0fb-be715e6eef29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modality: bmode\n",
      "Train: (517, 2)\n",
      "Val: (90, 2)\n",
      "Test: (40, 2)\n",
      "\n",
      "Modality: enhanced\n",
      "Train: (517, 2)\n",
      "Val: (90, 2)\n",
      "Test: (40, 2)\n",
      "\n",
      "Modality: improved\n",
      "Train: (517, 2)\n",
      "Val: (90, 2)\n",
      "Test: (40, 2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# ==== Set Base Directory ====\n",
    "base_dir = \"/home/jupyter/fold1/fold1\"\n",
    "modalities = [\"bmode\", \"enhanced\", \"improved\"]  # All modalities we want to process\n",
    "\n",
    "# ==== Extract Image File Paths and Labels ====\n",
    "def load_image_paths_and_labels(base_path, label_name):\n",
    "    image_files = [f for f in os.listdir(base_path) if f.lower().endswith(\".png\")]\n",
    "    data = []\n",
    "\n",
    "    for img_name in image_files:\n",
    "\n",
    "        data.append((os.path.join(base_path, img_name), label_name))\n",
    "\n",
    "    return data\n",
    "\n",
    "# ==== Process Each Modality Separately ====\n",
    "for modality in modalities:\n",
    "    # Train paths\n",
    "    BENIGN_train_data_path = os.path.join(base_dir, \"train\", modality, \"benign\")\n",
    "    MALIGNANT_train_data_path = os.path.join(base_dir, \"train\", modality, \"malignant\")\n",
    "\n",
    "    # Validation paths\n",
    "    BENIGN_val_data_path = os.path.join(base_dir, \"val\", modality, \"benign\")\n",
    "    MALIGNANT_val_data_path = os.path.join(base_dir, \"val\", modality, \"malignant\")\n",
    "\n",
    "    # Test paths\n",
    "    BENIGN_test_data_path = os.path.join(base_dir, \"test\", modality, \"benign\")\n",
    "    MALIGNANT_test_data_path = os.path.join(base_dir, \"test\", modality, \"malignant\")\n",
    "\n",
    "    # Load data for both classes\n",
    "    benign_train_data = load_image_paths_and_labels(BENIGN_train_data_path, label_name=0)\n",
    "    malignant_train_data = load_image_paths_and_labels(MALIGNANT_train_data_path, label_name=1)\n",
    "\n",
    "    benign_val_data = load_image_paths_and_labels(BENIGN_val_data_path, label_name=0)\n",
    "    malignant_val_data = load_image_paths_and_labels(MALIGNANT_val_data_path, label_name=1)\n",
    "\n",
    "    benign_test_data = load_image_paths_and_labels(BENIGN_test_data_path, label_name=0)\n",
    "    malignant_test_data = load_image_paths_and_labels(MALIGNANT_test_data_path, label_name=1)\n",
    "\n",
    "    # Merge and shuffle\n",
    "    all_train_data = benign_train_data + malignant_train_data\n",
    "    all_val_data = benign_val_data + malignant_val_data\n",
    "    all_test_data = benign_test_data + malignant_test_data\n",
    "\n",
    "    # Convert to DataFrame with modality-specific variable names\n",
    "    globals()[f\"df_train_{modality}\"] = pd.DataFrame(all_train_data, columns=[\"image_path\", \"label\"])\n",
    "    globals()[f\"df_val_{modality}\"] = pd.DataFrame(all_val_data, columns=[\"image_path\", \"label\"])\n",
    "    globals()[f\"df_test_{modality}\"] = pd.DataFrame(all_test_data, columns=[\"image_path\", \"label\"])\n",
    "\n",
    "    # Print shapes\n",
    "    print(f\"\\nModality: {modality}\")\n",
    "    print(\"Train:\", globals()[f\"df_train_{modality}\"].shape)\n",
    "    print(\"Val:\", globals()[f\"df_val_{modality}\"].shape)\n",
    "    print(\"Test:\", globals()[f\"df_test_{modality}\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dba2a99-de16-42c4-a1f3-bdd1f39d5042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
